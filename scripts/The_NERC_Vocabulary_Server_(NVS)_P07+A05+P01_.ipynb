{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The NERC Vocabulary Server (NVS)_P07+A05+P01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTSVWdhydhHb"
      },
      "source": [
        "!pip install requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxZr27hUd4oP"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30JuefZBgcPC"
      },
      "source": [
        "Extraction des concepts skos avec leurs propriétés"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3nt8P4Ad9mR"
      },
      "source": [
        "def pretty_print(df):\n",
        "    return display(HTML(df.to_html().replace(\",\",\"<br>\")))\n",
        "    \n",
        "def get_preferred_label(html_content):\n",
        "    preferred_label = html_content.find('h2').text\n",
        "    return preferred_label\n",
        "\n",
        "def get_related(html_content):\n",
        "    p_list = []\n",
        "    element_list = []\n",
        "    untreated_related = [x.text for x in html_content.find(\"a\", text=\"Related\").find_parent('th').find_next_sibling('td').find_all('a')]\n",
        "    for i in range(len(untreated_related)):\n",
        "        if (i % 2) == 0:\n",
        "            p_list.append(untreated_related[i])\n",
        "        else:\n",
        "            element_list.append(untreated_related[i])\n",
        "    related = [x[0] + ': ' + x[1] for x in zip(p_list, element_list)]\n",
        "    return (','.join(related))\n",
        "\n",
        "def get_narrower(html_content):\n",
        "    p_list = []\n",
        "    element_list = []\n",
        "    untreated_narrower = [x.text for x in html_content.find(\"a\", text=\"Narrower\").find_parent('th').find_next_sibling('td').find_all('a')]\n",
        "    for i in range(len(untreated_narrower)):\n",
        "        if (i % 2) == 0:\n",
        "            p_list.append(untreated_narrower[i])\n",
        "        else:\n",
        "            element_list.append(untreated_narrower[i])\n",
        "    narrower = [x[0] + ': ' + x[1] for x in zip(p_list, element_list)]\n",
        "    return (','.join(narrower))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AN3qWCYpeI_Q"
      },
      "source": [
        "link_list=['http://vocab.nerc.ac.uk/collection/A05/','http://vocab.nerc.ac.uk/collection/P01/','http://vocab.nerc.ac.uk/collection/P07/']\n",
        "final_dic = {}\n",
        "for element in link_list:\n",
        "    print (element)\n",
        "    links = []\n",
        "    source = requests.get(element).text\n",
        "    soup = BeautifulSoup(source, 'html.parser')\n",
        "    table_rows = soup.find_all('td', class_='onefifty')\n",
        "    for row in table_rows:\n",
        "        link = row.find('a')\n",
        "        if link:\n",
        "            links.append(link['href'])\n",
        "    for link in links:\n",
        "        Identifier_link = requests.get(link).text\n",
        "        soup = BeautifulSoup(Identifier_link, 'html.parser')\n",
        "        identifier = link.split('/')[-2]\n",
        "        print (identifier)\n",
        "        try:\n",
        "            preferred_label = get_preferred_label(soup)\n",
        "        except:\n",
        "            preferred_label = None\n",
        "        try:\n",
        "            related = get_related(soup)\n",
        "        except:\n",
        "            related = None\n",
        "        try:\n",
        "            narrower = get_narrower(soup)\n",
        "        except:\n",
        "            narrower = None\n",
        "        final_dic[identifier] = {'Preferred Label' : preferred_label, 'Related' : related, 'Narrower' : narrower}\n",
        "with open(\"final_output.json\", 'w') as fich:\n",
        "        json.dump(final_dic, fich)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BrT7SdofngG"
      },
      "source": [
        "data =pd.DataFrame.from_dict(final_dic)\n",
        "pretty_print(data)\n",
        "data.to_csv(r'scrapped_data_from_NVS.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyY4ye53JuTT"
      },
      "source": [
        "data.to_excel(r'scrapped_data_from_NVS.xlsx', index= False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}